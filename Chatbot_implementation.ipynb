{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOmBsKaxZQHf1Ewl/CFHKdM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SagarSharma250/Chatbot/blob/main/Chatbot_implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "qWEO_0BSx0Rj"
      },
      "outputs": [],
      "source": [
        "# !pip install langchain\n",
        "# !pip install pypdf\n",
        "# !pip install cohere\n",
        "# !pip install qdrant-client\n",
        "# !pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import Libraries\n",
        "import os\n",
        "import langchain\n",
        "import gradio as gr"
      ],
      "metadata": {
        "id": "hrYX_OTnx-3z"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "# Filter out the LangChainDeprecationWarning\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "AD5B69Fcyw-G"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")\n",
        "os.chdir('/content/gdrive/MyDrive/Colab/Chatbot')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oa35NLBBy49I",
        "outputId": "2e454f38-d8a0-4d09-cf0b-ca9057e65207"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load content from PDF Document\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "loader = PyPDFLoader (\"./llm.pdf\")\n",
        "#Provide the respective file path of the PDF Document\n",
        "documents = loader.load()"
      ],
      "metadata": {
        "id": "qOvrY4_xyWSL"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZ9AWd_i2l2V",
        "outputId": "42cc53e3-a7e1-4ad9-ad3c-1d3558631ba3"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content=\"Large\\nlanguage\\nmodels\\n(LLMs)\\nrepresent\\na\\ngroundbreaking\\nadvancement\\nin\\nartificial\\nintelligence,\\nparticularly\\nin\\nnatural\\nlanguage\\nprocessing.\\nThese\\nmodels,\\nlike\\nOpenAI's\\nGPT\\n(Generative\\nPre-trained\\nTransformer)\\nseries,\\nare\\ncharacterized\\nby\\ntheir\\nimmense\\nsize\\nand\\ncomplexity,\\ntypically\\ncomprising\\nbillions\\nor\\neven\\ntrillions\\nof\\nparameters.\\nBy\\nleveraging\\nvast\\namounts\\nof\\ntext\\ndata\\nfrom\\nthe\\ninternet,\\nLLMs\\nare\\npre-trained\\non\\na\\ndiverse\\nrange\\nof\\nlinguistic\\ntasks,\\nenabling\\nthem\\nto\\nunderstand\\nand\\ngenerate\\nhuman-like\\ntext\\nacross\\nvarious\\ndomains\\nand\\nlanguages.\\nThis\\npre-training\\nphase\\nis\\ncrucial\\nas\\nit\\nallows\\nthe\\nmodel\\nto\\nlearn\\nintricate\\npatterns\\nand\\nnuances\\nof\\nlanguage,\\neffectively\\ncapturing\\nsemantic\\nrelationships\\nand\\ncontextual\\ninformation.\\nOne\\nof\\nthe\\nkey\\nstrengths\\nof\\nLLMs\\nlies\\nin\\ntheir\\nability\\nto\\nperform\\na\\nwide\\narray\\nof\\nnatural\\nlanguage\\nprocessing\\ntasks\\nwith\\nminimal\\nfine-tuning.\\nWhether\\nit's\\ntext\\ngeneration,\\nlanguage\\ntranslation,\\nsentiment\\nanalysis,\\nor\\nquestion\\nanswering,\\nthese\\nmodels\\ndemonstrate\\nremarkable\\nversatility\\nand\\nadaptability.\\nMoreover,\\nLLMs\\ncan\\ngenerate\\ncoherent\\nand\\ncontextually\\nrelevant\\ntext,\\noften\\nindistinguishable\\nfrom\\nthat\\nwritten\\nby\\nhumans.\\nThis\\ncapability\\nhas\\nprofound\\nimplications\\nacross\\nnumerous\\nindustries,\\nfrom\\ncontent\\ngeneration\\nand\\ncustomer\\nservice\\nto\\neducation\\nand\\nhealthcare.\\nBy\\nautomating\\nlabor-intensive\\ntasks\\nand\\nproviding\\ninsights\\nfrom\\nvast\\namounts\\nof\\ntextual\\ndata,\\nLLMs\\nhave\\nthe\\npotential\\nto\\nrevolutionize\\nhow\\nwe\\ninteract\\nwith\\ninformation\\nand\\ntechnology.\\nHowever,\\nthe\\ndeployment\\nof\\nlarge\\nlanguage\\nmodels\\nalso\\nraises\\nimportant\\nethical\\nand\\nsocietal\\nconcerns.\\nIssues\\nsuch\\nas\\nbias\\nin\\ntraining\\ndata,\\nmisinformation\\ngeneration,\\nand\\npotential\\njob\\ndisplacement\\nare\\nhotly\\ndebated\\ntopics.\\nMoreover,\\nthe\\nimmense\\ncomputational\\nresources\\nrequired\\nto\\ntrain\\nand\\nrun\\nthese\\nmodels\\ncontribute\\nto\\nconcerns\\nabout\\ntheir\\nenvironmental\\nimpact.\\nAs\\nresearchers\\nand\\npolicymakers\\ngrapple\\nwith\\nthese\\nchallenges,\\nthere\\nis\\na\\ngrowing\\nconsensus\\non\\nthe\\nneed\\nfor\\nresponsible\\ndevelopment\\nand\\ndeployment\\nof\\nLLMs.\\nInitiatives\\nsuch\\nas\\nethical\\nguidelines,\\ntransparency\\nstandards,\\nand\\nmodel\\nauditing\\nframeworks\\naim\\nto\\nmitigate\\nthese\\nrisks\\nand\\nensure\\nthat\\nLLMs\\nare\\nused\\nin\\nways\\nthat\\nbenefit\\nsociety\\nwhile\\nminimizing\\nharm.\", metadata={'source': './llm.pdf', 'page': 0})]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Print PDF Document Content\n",
        "#Based on the Volume of the Content of the Document we can print all documents or few extracts\n",
        "# doc = documents[0]\n",
        "# page_content = doc.page_content[:10000]\n",
        "# print(page_content[:2000])"
      ],
      "metadata": {
        "id": "_DHrbLzPyvF5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Split the Document into chunks for embedding and vector storage.\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap = 50)\n",
        "all_splits = text_splitter.split_documents(documents)"
      ],
      "metadata": {
        "id": "Uwh8ORrgze9z"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(all_splits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIn8RQXIzlGZ",
        "outputId": "864fd3e5-9495-43a4-f0da-e47155074097"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Document(page_content=\"Large\\nlanguage\\nmodels\\n(LLMs)\\nrepresent\\na\\ngroundbreaking\\nadvancement\\nin\\nartificial\\nintelligence,\\nparticularly\\nin\\nnatural\\nlanguage\\nprocessing.\\nThese\\nmodels,\\nlike\\nOpenAI's\\nGPT\\n(Generative\\nPre-trained\\nTransformer)\\nseries,\\nare\\ncharacterized\\nby\\ntheir\\nimmense\\nsize\\nand\\ncomplexity,\\ntypically\\ncomprising\\nbillions\\nor\\neven\\ntrillions\\nof\\nparameters.\\nBy\\nleveraging\\nvast\\namounts\\nof\\ntext\\ndata\\nfrom\\nthe\\ninternet,\\nLLMs\\nare\\npre-trained\\non\\na\\ndiverse\\nrange\\nof\\nlinguistic\\ntasks,\\nenabling\\nthem\\nto\\nunderstand\\nand\\ngenerate\", metadata={'source': './llm.pdf', 'page': 0}), Document(page_content=\"tasks,\\nenabling\\nthem\\nto\\nunderstand\\nand\\ngenerate\\nhuman-like\\ntext\\nacross\\nvarious\\ndomains\\nand\\nlanguages.\\nThis\\npre-training\\nphase\\nis\\ncrucial\\nas\\nit\\nallows\\nthe\\nmodel\\nto\\nlearn\\nintricate\\npatterns\\nand\\nnuances\\nof\\nlanguage,\\neffectively\\ncapturing\\nsemantic\\nrelationships\\nand\\ncontextual\\ninformation.\\nOne\\nof\\nthe\\nkey\\nstrengths\\nof\\nLLMs\\nlies\\nin\\ntheir\\nability\\nto\\nperform\\na\\nwide\\narray\\nof\\nnatural\\nlanguage\\nprocessing\\ntasks\\nwith\\nminimal\\nfine-tuning.\\nWhether\\nit's\\ntext\\ngeneration,\\nlanguage\\ntranslation,\\nsentiment\\nanalysis,\", metadata={'source': './llm.pdf', 'page': 0}), Document(page_content='language\\ntranslation,\\nsentiment\\nanalysis,\\nor\\nquestion\\nanswering,\\nthese\\nmodels\\ndemonstrate\\nremarkable\\nversatility\\nand\\nadaptability.\\nMoreover,\\nLLMs\\ncan\\ngenerate\\ncoherent\\nand\\ncontextually\\nrelevant\\ntext,\\noften\\nindistinguishable\\nfrom\\nthat\\nwritten\\nby\\nhumans.\\nThis\\ncapability\\nhas\\nprofound\\nimplications\\nacross\\nnumerous\\nindustries,\\nfrom\\ncontent\\ngeneration\\nand\\ncustomer\\nservice\\nto\\neducation\\nand\\nhealthcare.\\nBy\\nautomating\\nlabor-intensive\\ntasks\\nand\\nproviding\\ninsights\\nfrom\\nvast\\namounts\\nof\\ntextual\\ndata,\\nLLMs', metadata={'source': './llm.pdf', 'page': 0}), Document(page_content='insights\\nfrom\\nvast\\namounts\\nof\\ntextual\\ndata,\\nLLMs\\nhave\\nthe\\npotential\\nto\\nrevolutionize\\nhow\\nwe\\ninteract\\nwith\\ninformation\\nand\\ntechnology.\\nHowever,\\nthe\\ndeployment\\nof\\nlarge\\nlanguage\\nmodels\\nalso\\nraises\\nimportant\\nethical\\nand\\nsocietal\\nconcerns.\\nIssues\\nsuch\\nas\\nbias\\nin\\ntraining\\ndata,\\nmisinformation\\ngeneration,\\nand\\npotential\\njob\\ndisplacement\\nare\\nhotly\\ndebated\\ntopics.\\nMoreover,\\nthe\\nimmense\\ncomputational\\nresources\\nrequired\\nto\\ntrain\\nand\\nrun\\nthese\\nmodels\\ncontribute\\nto\\nconcerns\\nabout\\ntheir\\nenvironmental\\nimpact.', metadata={'source': './llm.pdf', 'page': 0}), Document(page_content='to\\nconcerns\\nabout\\ntheir\\nenvironmental\\nimpact.\\nAs\\nresearchers\\nand\\npolicymakers\\ngrapple\\nwith\\nthese\\nchallenges,\\nthere\\nis\\na\\ngrowing\\nconsensus\\non\\nthe\\nneed\\nfor\\nresponsible\\ndevelopment\\nand\\ndeployment\\nof\\nLLMs.\\nInitiatives\\nsuch\\nas\\nethical\\nguidelines,\\ntransparency\\nstandards,\\nand\\nmodel\\nauditing\\nframeworks\\naim\\nto\\nmitigate\\nthese\\nrisks\\nand\\nensure\\nthat\\nLLMs\\nare\\nused\\nin\\nways\\nthat\\nbenefit\\nsociety\\nwhile\\nminimizing\\nharm.', metadata={'source': './llm.pdf', 'page': 0})]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain.embeddings.cohere import CohereEmbeddings\n",
        "from langchain.vectorstores import Qdrant\n",
        "os.environ['COHERE_API_KEY'] =  '***sdlan***'    #Set the Cohere API Key\n",
        "embeddings = CohereEmbeddings(model = \"multilingual-22-12\")\n",
        "db = Qdrant.from_documents(all_splits, embeddings, location=\":memory:\", collection_name=\"all_splits\", distance_func=\"Dot\")"
      ],
      "metadata": {
        "id": "cDruyH8kzm5l"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import langchain\n",
        "langchain.debug = False\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.llms import Cohere\n",
        "#temperature defines randomness of the output 0 defines least randomness 1 defines maximum randomness\n",
        "qa = RetrievalQA.from_chain_type(llm=Cohere(model=\"command-nightly\",temperature=0.5),\n",
        "                                 chain_type=\"stuff\",\n",
        "                                 retriever=db.as_retriever(),\n",
        "                                 return_source_documents=True)"
      ],
      "metadata": {
        "id": "UcsVjvwx0G2N"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "questions = [\n",
        "           \"How are language Translators job redefined ?\",\n",
        "           \"What did the article say about Sam?\",\n",
        "           \"What did the article say about Covid?\"\n",
        "           ]"
      ],
      "metadata": {
        "id": "bZ0C31Ww0UhC"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for question in questions:\n",
        "  answer = qa({\"query\": question})\n",
        "  print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnTzs_c50lUc",
        "outputId": "d1de407d-2e2b-4548-910c-782247090aa1"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'query': 'How are language Translators job redefined ?', 'result': \"I don't know.\", 'source_documents': [Document(page_content=\"tasks,\\nenabling\\nthem\\nto\\nunderstand\\nand\\ngenerate\\nhuman-like\\ntext\\nacross\\nvarious\\ndomains\\nand\\nlanguages.\\nThis\\npre-training\\nphase\\nis\\ncrucial\\nas\\nit\\nallows\\nthe\\nmodel\\nto\\nlearn\\nintricate\\npatterns\\nand\\nnuances\\nof\\nlanguage,\\neffectively\\ncapturing\\nsemantic\\nrelationships\\nand\\ncontextual\\ninformation.\\nOne\\nof\\nthe\\nkey\\nstrengths\\nof\\nLLMs\\nlies\\nin\\ntheir\\nability\\nto\\nperform\\na\\nwide\\narray\\nof\\nnatural\\nlanguage\\nprocessing\\ntasks\\nwith\\nminimal\\nfine-tuning.\\nWhether\\nit's\\ntext\\ngeneration,\\nlanguage\\ntranslation,\\nsentiment\\nanalysis,\", metadata={'source': './llm.pdf', 'page': 0, '_id': '817dedfc46184517b2b98b596212b4e3', '_collection_name': 'all_splits'}), Document(page_content='language\\ntranslation,\\nsentiment\\nanalysis,\\nor\\nquestion\\nanswering,\\nthese\\nmodels\\ndemonstrate\\nremarkable\\nversatility\\nand\\nadaptability.\\nMoreover,\\nLLMs\\ncan\\ngenerate\\ncoherent\\nand\\ncontextually\\nrelevant\\ntext,\\noften\\nindistinguishable\\nfrom\\nthat\\nwritten\\nby\\nhumans.\\nThis\\ncapability\\nhas\\nprofound\\nimplications\\nacross\\nnumerous\\nindustries,\\nfrom\\ncontent\\ngeneration\\nand\\ncustomer\\nservice\\nto\\neducation\\nand\\nhealthcare.\\nBy\\nautomating\\nlabor-intensive\\ntasks\\nand\\nproviding\\ninsights\\nfrom\\nvast\\namounts\\nof\\ntextual\\ndata,\\nLLMs', metadata={'source': './llm.pdf', 'page': 0, '_id': 'c5e5ad82078943998509b87e57479982', '_collection_name': 'all_splits'}), Document(page_content=\"Large\\nlanguage\\nmodels\\n(LLMs)\\nrepresent\\na\\ngroundbreaking\\nadvancement\\nin\\nartificial\\nintelligence,\\nparticularly\\nin\\nnatural\\nlanguage\\nprocessing.\\nThese\\nmodels,\\nlike\\nOpenAI's\\nGPT\\n(Generative\\nPre-trained\\nTransformer)\\nseries,\\nare\\ncharacterized\\nby\\ntheir\\nimmense\\nsize\\nand\\ncomplexity,\\ntypically\\ncomprising\\nbillions\\nor\\neven\\ntrillions\\nof\\nparameters.\\nBy\\nleveraging\\nvast\\namounts\\nof\\ntext\\ndata\\nfrom\\nthe\\ninternet,\\nLLMs\\nare\\npre-trained\\non\\na\\ndiverse\\nrange\\nof\\nlinguistic\\ntasks,\\nenabling\\nthem\\nto\\nunderstand\\nand\\ngenerate\", metadata={'source': './llm.pdf', 'page': 0, '_id': '5c470fc195f14642996ab4cf833dcac6', '_collection_name': 'all_splits'}), Document(page_content='insights\\nfrom\\nvast\\namounts\\nof\\ntextual\\ndata,\\nLLMs\\nhave\\nthe\\npotential\\nto\\nrevolutionize\\nhow\\nwe\\ninteract\\nwith\\ninformation\\nand\\ntechnology.\\nHowever,\\nthe\\ndeployment\\nof\\nlarge\\nlanguage\\nmodels\\nalso\\nraises\\nimportant\\nethical\\nand\\nsocietal\\nconcerns.\\nIssues\\nsuch\\nas\\nbias\\nin\\ntraining\\ndata,\\nmisinformation\\ngeneration,\\nand\\npotential\\njob\\ndisplacement\\nare\\nhotly\\ndebated\\ntopics.\\nMoreover,\\nthe\\nimmense\\ncomputational\\nresources\\nrequired\\nto\\ntrain\\nand\\nrun\\nthese\\nmodels\\ncontribute\\nto\\nconcerns\\nabout\\ntheir\\nenvironmental\\nimpact.', metadata={'source': './llm.pdf', 'page': 0, '_id': '3644581bad6d475e845cd8f2326313cb', '_collection_name': 'all_splits'})]}\n",
            "{'query': 'What did the article say about Sam?', 'result': \"I don't know.\", 'source_documents': [Document(page_content='language\\ntranslation,\\nsentiment\\nanalysis,\\nor\\nquestion\\nanswering,\\nthese\\nmodels\\ndemonstrate\\nremarkable\\nversatility\\nand\\nadaptability.\\nMoreover,\\nLLMs\\ncan\\ngenerate\\ncoherent\\nand\\ncontextually\\nrelevant\\ntext,\\noften\\nindistinguishable\\nfrom\\nthat\\nwritten\\nby\\nhumans.\\nThis\\ncapability\\nhas\\nprofound\\nimplications\\nacross\\nnumerous\\nindustries,\\nfrom\\ncontent\\ngeneration\\nand\\ncustomer\\nservice\\nto\\neducation\\nand\\nhealthcare.\\nBy\\nautomating\\nlabor-intensive\\ntasks\\nand\\nproviding\\ninsights\\nfrom\\nvast\\namounts\\nof\\ntextual\\ndata,\\nLLMs', metadata={'source': './llm.pdf', 'page': 0, '_id': 'c5e5ad82078943998509b87e57479982', '_collection_name': 'all_splits'}), Document(page_content='insights\\nfrom\\nvast\\namounts\\nof\\ntextual\\ndata,\\nLLMs\\nhave\\nthe\\npotential\\nto\\nrevolutionize\\nhow\\nwe\\ninteract\\nwith\\ninformation\\nand\\ntechnology.\\nHowever,\\nthe\\ndeployment\\nof\\nlarge\\nlanguage\\nmodels\\nalso\\nraises\\nimportant\\nethical\\nand\\nsocietal\\nconcerns.\\nIssues\\nsuch\\nas\\nbias\\nin\\ntraining\\ndata,\\nmisinformation\\ngeneration,\\nand\\npotential\\njob\\ndisplacement\\nare\\nhotly\\ndebated\\ntopics.\\nMoreover,\\nthe\\nimmense\\ncomputational\\nresources\\nrequired\\nto\\ntrain\\nand\\nrun\\nthese\\nmodels\\ncontribute\\nto\\nconcerns\\nabout\\ntheir\\nenvironmental\\nimpact.', metadata={'source': './llm.pdf', 'page': 0, '_id': '3644581bad6d475e845cd8f2326313cb', '_collection_name': 'all_splits'}), Document(page_content=\"tasks,\\nenabling\\nthem\\nto\\nunderstand\\nand\\ngenerate\\nhuman-like\\ntext\\nacross\\nvarious\\ndomains\\nand\\nlanguages.\\nThis\\npre-training\\nphase\\nis\\ncrucial\\nas\\nit\\nallows\\nthe\\nmodel\\nto\\nlearn\\nintricate\\npatterns\\nand\\nnuances\\nof\\nlanguage,\\neffectively\\ncapturing\\nsemantic\\nrelationships\\nand\\ncontextual\\ninformation.\\nOne\\nof\\nthe\\nkey\\nstrengths\\nof\\nLLMs\\nlies\\nin\\ntheir\\nability\\nto\\nperform\\na\\nwide\\narray\\nof\\nnatural\\nlanguage\\nprocessing\\ntasks\\nwith\\nminimal\\nfine-tuning.\\nWhether\\nit's\\ntext\\ngeneration,\\nlanguage\\ntranslation,\\nsentiment\\nanalysis,\", metadata={'source': './llm.pdf', 'page': 0, '_id': '817dedfc46184517b2b98b596212b4e3', '_collection_name': 'all_splits'}), Document(page_content=\"Large\\nlanguage\\nmodels\\n(LLMs)\\nrepresent\\na\\ngroundbreaking\\nadvancement\\nin\\nartificial\\nintelligence,\\nparticularly\\nin\\nnatural\\nlanguage\\nprocessing.\\nThese\\nmodels,\\nlike\\nOpenAI's\\nGPT\\n(Generative\\nPre-trained\\nTransformer)\\nseries,\\nare\\ncharacterized\\nby\\ntheir\\nimmense\\nsize\\nand\\ncomplexity,\\ntypically\\ncomprising\\nbillions\\nor\\neven\\ntrillions\\nof\\nparameters.\\nBy\\nleveraging\\nvast\\namounts\\nof\\ntext\\ndata\\nfrom\\nthe\\ninternet,\\nLLMs\\nare\\npre-trained\\non\\na\\ndiverse\\nrange\\nof\\nlinguistic\\ntasks,\\nenabling\\nthem\\nto\\nunderstand\\nand\\ngenerate\", metadata={'source': './llm.pdf', 'page': 0, '_id': '5c470fc195f14642996ab4cf833dcac6', '_collection_name': 'all_splits'})]}\n",
            "{'query': 'What did the article say about Covid?', 'result': 'The article does not mention Covid.', 'source_documents': [Document(page_content='insights\\nfrom\\nvast\\namounts\\nof\\ntextual\\ndata,\\nLLMs\\nhave\\nthe\\npotential\\nto\\nrevolutionize\\nhow\\nwe\\ninteract\\nwith\\ninformation\\nand\\ntechnology.\\nHowever,\\nthe\\ndeployment\\nof\\nlarge\\nlanguage\\nmodels\\nalso\\nraises\\nimportant\\nethical\\nand\\nsocietal\\nconcerns.\\nIssues\\nsuch\\nas\\nbias\\nin\\ntraining\\ndata,\\nmisinformation\\ngeneration,\\nand\\npotential\\njob\\ndisplacement\\nare\\nhotly\\ndebated\\ntopics.\\nMoreover,\\nthe\\nimmense\\ncomputational\\nresources\\nrequired\\nto\\ntrain\\nand\\nrun\\nthese\\nmodels\\ncontribute\\nto\\nconcerns\\nabout\\ntheir\\nenvironmental\\nimpact.', metadata={'source': './llm.pdf', 'page': 0, '_id': '3644581bad6d475e845cd8f2326313cb', '_collection_name': 'all_splits'}), Document(page_content='language\\ntranslation,\\nsentiment\\nanalysis,\\nor\\nquestion\\nanswering,\\nthese\\nmodels\\ndemonstrate\\nremarkable\\nversatility\\nand\\nadaptability.\\nMoreover,\\nLLMs\\ncan\\ngenerate\\ncoherent\\nand\\ncontextually\\nrelevant\\ntext,\\noften\\nindistinguishable\\nfrom\\nthat\\nwritten\\nby\\nhumans.\\nThis\\ncapability\\nhas\\nprofound\\nimplications\\nacross\\nnumerous\\nindustries,\\nfrom\\ncontent\\ngeneration\\nand\\ncustomer\\nservice\\nto\\neducation\\nand\\nhealthcare.\\nBy\\nautomating\\nlabor-intensive\\ntasks\\nand\\nproviding\\ninsights\\nfrom\\nvast\\namounts\\nof\\ntextual\\ndata,\\nLLMs', metadata={'source': './llm.pdf', 'page': 0, '_id': 'c5e5ad82078943998509b87e57479982', '_collection_name': 'all_splits'}), Document(page_content='to\\nconcerns\\nabout\\ntheir\\nenvironmental\\nimpact.\\nAs\\nresearchers\\nand\\npolicymakers\\ngrapple\\nwith\\nthese\\nchallenges,\\nthere\\nis\\na\\ngrowing\\nconsensus\\non\\nthe\\nneed\\nfor\\nresponsible\\ndevelopment\\nand\\ndeployment\\nof\\nLLMs.\\nInitiatives\\nsuch\\nas\\nethical\\nguidelines,\\ntransparency\\nstandards,\\nand\\nmodel\\nauditing\\nframeworks\\naim\\nto\\nmitigate\\nthese\\nrisks\\nand\\nensure\\nthat\\nLLMs\\nare\\nused\\nin\\nways\\nthat\\nbenefit\\nsociety\\nwhile\\nminimizing\\nharm.', metadata={'source': './llm.pdf', 'page': 0, '_id': 'c4015f5d61b14549ab98373009f24626', '_collection_name': 'all_splits'}), Document(page_content=\"tasks,\\nenabling\\nthem\\nto\\nunderstand\\nand\\ngenerate\\nhuman-like\\ntext\\nacross\\nvarious\\ndomains\\nand\\nlanguages.\\nThis\\npre-training\\nphase\\nis\\ncrucial\\nas\\nit\\nallows\\nthe\\nmodel\\nto\\nlearn\\nintricate\\npatterns\\nand\\nnuances\\nof\\nlanguage,\\neffectively\\ncapturing\\nsemantic\\nrelationships\\nand\\ncontextual\\ninformation.\\nOne\\nof\\nthe\\nkey\\nstrengths\\nof\\nLLMs\\nlies\\nin\\ntheir\\nability\\nto\\nperform\\na\\nwide\\narray\\nof\\nnatural\\nlanguage\\nprocessing\\ntasks\\nwith\\nminimal\\nfine-tuning.\\nWhether\\nit's\\ntext\\ngeneration,\\nlanguage\\ntranslation,\\nsentiment\\nanalysis,\", metadata={'source': './llm.pdf', 'page': 0, '_id': '817dedfc46184517b2b98b596212b4e3', '_collection_name': 'all_splits'})]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import Cohere\n",
        "llm = Cohere(model = \"command\", temperature=0.5)"
      ],
      "metadata": {
        "id": "dB9uRYD10mrE"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.chains.conversation.memory import ConversationSummaryMemory\n",
        "#Setup Chat History\n",
        "#The chat_history variable keeps track of the conversation history,\n",
        "#storing the user queries #and the chatbot's responses\n",
        "#This allows the chatbot to maintain context and provide relevant answers\n",
        "# based on past interactions.\n",
        "chat_history = []\n",
        "qa = ConversationalRetrievalChain.from_llm(\n",
        "    llm = llm,\n",
        "    chain_type = \"stuff\",\n",
        "    memory = ConversationSummaryMemory(llm = llm, memory_key='chat_history', input_key='question', output_key= 'answer', return_messages=True),\n",
        "    retriever = db.as_retriever(),\n",
        "    return_source_documents=False\n",
        ")"
      ],
      "metadata": {
        "id": "9MwK1wmu0qVa"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementation using Gardio Interface"
      ],
      "metadata": {
        "id": "U-oO7YEkJ-qI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import sys\n",
        "\n",
        "# Define the function to update user info\n",
        "user_info = {'data': []}\n",
        "update_info_result = ''\n",
        "\n",
        "def update_user_info(name, phone_number, email):\n",
        "    global update_info_result\n",
        "    user_info['data'].append({\n",
        "        'name': name,\n",
        "        'phone_number': phone_number,\n",
        "        'email': email\n",
        "    })\n",
        "    update_info_result = \"User info updated successfully.\"\n",
        "\n",
        "# Define the function for Document QA\n",
        "def QandA(question):\n",
        "    global chat_history\n",
        "    result = qa({\"question\": question, \"chat_history\": chat_history})\n",
        "    chat_history.append((question, result['answer']))\n",
        "    return result['answer']\n",
        "\n",
        "# Define the Gradio interface for updating user info\n",
        "def update_info(name, phone_number, email):\n",
        "    update_user_info(name, phone_number, email)\n",
        "    return \"User info updated successfully.\"\n",
        "\n",
        "UpdateInfoUI = gr.Interface(update_info,\n",
        "                             inputs=[\"text\", \"text\", \"text\"],\n",
        "                             outputs=\"text\",\n",
        "                             title=\"Update User Info\",\n",
        "                             description=\"Enter your name, phone number, and email to update user information.\")\n",
        "\n",
        "# Define the Gradio interface for chatting with the chatbot\n",
        "def chat_interface():\n",
        "    return gr.Interface(QandA,\n",
        "                        inputs=\"text\",\n",
        "                        outputs=\"text\",\n",
        "                        title=\"Chat with Chatbot\",\n",
        "                        description=\"Ask your questions here.\")\n",
        "\n",
        "# Launch the Gradio interfaces\n",
        "update_info_result = UpdateInfoUI.launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "Fwg50rt84Q4t",
        "outputId": "ba4ae4ee-5ae7-4f06-8c3f-477b390d9d0d"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://dd89a2477ca1f9f0fa.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://dd89a2477ca1f9f0fa.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if user info was updated successfully\n",
        "if update_info_result == \"User info updated successfully.\":\n",
        "    # Close the \"Update User Info\" interface\n",
        "    UpdateInfoUI.close()\n",
        "    # Launch the interface for chatting with the chatbot\n",
        "    chat_interface().launch(share=True)\n",
        "\n",
        "# Initialize chat history\n",
        "chat_history = []"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "id": "FTIsLvG98cIL",
        "outputId": "05b8c5f4-5c9e-4b56-86a3-3252b4a71bc1"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing server running on port: 7862\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://d3683ce47f8d93c1ee.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://d3683ce47f8d93c1ee.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notebook implementation of User form and chatbot query"
      ],
      "metadata": {
        "id": "9I0o7u9LKGCE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "# Define the function to update user info\n",
        "user_info = {'data': []}\n",
        "update_info_result = ''\n",
        "\n",
        "def update_user_info(name, phone_number, email):\n",
        "    global update_info_result\n",
        "    user_info['data'].append({\n",
        "        'name': name,\n",
        "        'phone_number': phone_number,\n",
        "        'email': email\n",
        "    })\n",
        "    update_info_result = \"User info updated successfully.\"\n",
        "\n",
        "# Define the function for Document QA\n",
        "def QandA(question):\n",
        "    global chat_history\n",
        "    result = qa({\"question\": question, \"chat_history\": chat_history})\n",
        "    chat_history.append((question, result['answer']))\n",
        "    return result['answer']\n",
        "\n",
        "# Define the Gradio interface for chatting with the chatbot\n",
        "def chat_interface():\n",
        "    if update_info_result !=\"User info updated successfully.\":\n",
        "      name = input(\"Your Name: \")\n",
        "      phone_number = input(\"Your Phone Number: \")\n",
        "      email = input(\"Your Email: \")\n",
        "      update_user_info(name,phone_number,email)\n",
        "    while(True):\n",
        "        print(\"Enter your query to the chatbot\")\n",
        "        question = input(\"Your Query:\")\n",
        "        if(question=='quit'):\n",
        "          break\n",
        "        else:\n",
        "          answer=QandA(question)\n",
        "          print(answer)"
      ],
      "metadata": {
        "id": "5vvJn1m0Hd-K"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_interface()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "We9fxR9I8l3k",
        "outputId": "83322b37-2b5d-45b6-b99d-f07b4a174386"
      },
      "execution_count": 63,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your Name: ss\n",
            "Your Phone Number: 9865875\n",
            "Your Email: ss@gmail.com\n",
            "Enter your query to the chatbot\n",
            "Your Query:explain about deployment of large language models?\n",
            " The deployment of LLMs raises several key ethical and societal concerns. Here are three examples of these concerns: \n",
            "\n",
            "1. Environmental impact: One significant concern is the astronomical environmental impact of LLMs. These models require immense computational resources to train and operate, leading to substantial energy consumption and carbon emissions. This is especially problematic in the current climate crisis, as AI technologies contribute to greenhouse gas emissions and the overall climate impact of the tech sector. \n",
            "\n",
            "2. Bias in training data: Another key concern is bias in the training data that is used to teach the LLMs. If the data is biased, the models themselves can reflect and even amplify such biases, leading to discriminatory or unfair outputs. This can have serious societal consequences, especially in sensitive domains like law, finance, and healthcare, where unbiased results are essential. \n",
            "\n",
            "3. Misinformation generation: Large Language Models have the potential to generate misinformation, which can be difficult to detect by unsuspecting users. Whether through deliberate misuse or unintentional errors, LLMs can produce false or misleading information, leading to potential harm to individuals, communities, and society at large. \n",
            "\n",
            "These concerns should be actively addressed through responsible development, careful curation of training data, and ongoing monitoring and auditing of LLMs to ensure their safe and\n",
            "Enter your query to the chatbot\n",
            "Your Query:what is the key strength of llm?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.llms.cohere:Retrying langchain_community.llms.cohere.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised TooManyRequestsError: status_code: 429, body: {'message': \"You are using a Trial key, which is limited to 5 API calls / minute. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.com/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions\"}.\n",
            "WARNING:langchain_community.llms.cohere:Retrying langchain_community.llms.cohere.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised TooManyRequestsError: status_code: 429, body: {'message': \"You are using a Trial key, which is limited to 5 API calls / minute. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.com/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions\"}.\n",
            "WARNING:langchain_community.llms.cohere:Retrying langchain_community.llms.cohere.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised TooManyRequestsError: status_code: 429, body: {'message': \"You are using a Trial key, which is limited to 5 API calls / minute. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.com/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions\"}.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Large Language Models (LLMs) have a number of benefits, but one of the key advantages is their ability to perform a wide array of language processing tasks with minimal fine-tuning. This means that these models can understand and generate human-like text across various domains and languages with ease. They can be applied to text generation, language translation, sentiment analysis, and question answering tasks, demonstrating remarkable versatility and adaptability. \n",
            "\n",
            "This advantage arises from the pre-training phase of these models, which allows them to learn intricate patterns and nuances of language. effectively capturing semantic relationships and contextual information. \n",
            "Enter your query to the chatbot\n",
            "Your Query:quit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_info"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Se6QvuZv7OmY",
        "outputId": "2ad4ba50-35a0-4818-8911-f9cf1fe5a505"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'data': [{'name': 'ss', 'phone_number': '9865875', 'email': 'ss@gmail.com'}]}"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ME4_lZQXLyA4"
      },
      "execution_count": 57,
      "outputs": []
    }
  ]
}